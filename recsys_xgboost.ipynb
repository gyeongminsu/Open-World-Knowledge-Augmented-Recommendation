{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home2/kkms4641/miniconda3\n",
      "LLM                   *  /home2/kkms4641/miniconda3/envs/LLM\n",
      "LLM2                     /home2/kkms4641/miniconda3/envs/LLM2\n",
      "diffusion                /home2/kkms4641/miniconda3/envs/diffusion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/preprocess/preprocess_amz.py:453: SyntaxWarning: invalid escape sequence '\\%'\n",
      "  f'& {item_avg:.1f}& {add_comma(interact_num)}& {sparsity:.2f}\\%&{add_comma(attribute_num)}&'\n",
      "total review 27164983 review w/o rating 0 0.0\n",
      "../data/amz/raw_data/Books_5.json.gz Raw data has been processed! Lower than 0.0 are deleted!\n",
      "User 60-core complete! Item 40-core complete!\n",
      "get meta infos\n",
      "no different item num\n",
      "Total User: 11906, Avg User: 133.1406, Min Len: 60, Max Len: 2552\n",
      "Total Item: 17332, Avg Item: 91.4593, Min Inter: 40, Max Inter: 2121\n",
      "Iteraction Num: 1585172, Sparsity: 99.23%\n",
      "defaultdict(<class 'int'>, {5.0: 960282, 4.0: 442125, 3.0: 131475, 2.0: 35807, 1.0: 15483}) 0.8847033634204995\n",
      "0.6057904126492267\n",
      "user items sample: [[5919, 5706, 4858, 4758, 2744, 4341, 272, 13293, 4416, 5103, 3286, 13294, 147, 10449, 1836, 4352, 15997, 3177, 9561, 6179, 2516, 13295, 12550, 6357, 3376, 9379, 9371, 771, 15281, 12614, 2078, 2447, 9642, 10736, 7417, 7161, 17218, 4549, 13296, 5130, 5135, 9575, 2065, 10877, 15221, 6475, 781, 2362, 15222, 12769, 10752, 5162, 2448, 7080, 15224, 3317, 12748, 14652, 6487, 14701, 5170, 11587, 14101, 14700, 5183, 8273, 9597, 3309, 804, 8928, 3315, 9598, 7459, 15207, 13931, 294, 13517, 309, 13448, 2503, 12852, 6499, 9611, 10258, 9643, 15527, 1779, 13564, 7471, 505, 451, 11829, 481, 10782, 5652, 5229, 825, 13568, 6502, 10084, 10261, 6503, 6505, 14272, 486, 4294, 6879, 4297, 2132, 6892, 850, 1101, 6905, 6913, 7504, 15235], [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0]]\n",
      "Begin extracting meta infos...\n",
      "before delete, attribute num:5472\n",
      "before delete, attribute num:5472\n",
      "attributes len, Min:2, Max:2, Avg.:2.0000\n",
      "itemid2title sample\n",
      "Title: Love's Labour's Lost: Performed by Derek Jacobi, Geraldine McEwan & Cast\n",
      "Brand: Visit Amazon's William Shakespeare Page\n",
      "Category: Literature & Fiction\n",
      "Title: Othello: Complete & Unabridged\n",
      "Brand: Visit Amazon's William Shakespeare Page\n",
      "Category: New, Used & Rental Textbooks\n",
      "Title: Lion, the Witch and the Wardrobe\n",
      "Brand: Visit Amazon's C. S. Lewis Page\n",
      "Category: Humor & Entertainment\n",
      "Title: Magician's Nephew - Folio Society Hardcover\n",
      "Brand: Visit Amazon's C.S. Lewis Page\n",
      "Category: Christian Books & Bibles\n",
      "Title: PREY.\n",
      "Brand: Visit Amazon's Michael. Crichton Page\n",
      "Category: Mystery, Thriller & Suspense\n",
      "Title: Gilead\n",
      "Brand: Visit Amazon's Marilynne Robinson Page\n",
      "Category: Literature & Fiction\n",
      "Title: For Whom the Bell Tolls\n",
      "Brand: ernest hemingway\n",
      "Category: Literature & Fiction\n",
      "Title: North and South\n",
      "Brand: Visit Amazon's John Jakes Page\n",
      "Category: Literature & Fiction\n",
      "Title: The Demon Lover\n",
      "Brand: Visit Amazon's Victoria Holt Page\n",
      "Category: Literature & Fiction\n",
      "Title: Kiss The Girls\n",
      "Brand: Visit Amazon's James Patterson Page\n",
      "Category: Mystery, Thriller & Suspense\n",
      "Title: A Feast for Crows (Song of Ice and Fire)\n",
      "Brand: Visit Amazon's George R.R. Martin Page\n",
      "Category: Literature & Fiction\n",
      "Title: The Golden Fool (Tawny Man)\n",
      "Brand: Visit Amazon's Robin Hobb Page\n",
      "Category: Science Fiction & Fantasy\n",
      "Title: A Dance with Dragons\n",
      "Brand: Visit Amazon's George R.R. Martin Page\n",
      "Category: Science Fiction & Fantasy\n",
      "Title: Jack And Jill\n",
      "Brand: Visit Amazon's James Patterson Page\n",
      "Category: Literature & Fiction\n",
      "Title: The Other Boleyn Girl\n",
      "Brand: Philippa GREGORY\n",
      "Category: Literature & Fiction\n",
      "Title: Dracula (Collins Drama)\n",
      "Brand: Jan Needle\n",
      "Category: Mystery, Thriller &amp; Suspense\n",
      "Title: Little Women\n",
      "Brand: Louisa May Alcott\n",
      "Category: Literature &amp; Fiction\n",
      "Title: Ross Poldark :POLDARK\n",
      "Brand: Visit Amazon's Winston Graham Page\n",
      "Category: Literature &amp; Fiction\n",
      "Title: Bloodline\n",
      "Brand: Visit Amazon's Sidney Sheldon Page\n",
      "Category: Literature &amp; Fiction\n",
      "Title: Along Came a Spider\n",
      "Brand: Visit Amazon's James Patterson Page\n",
      "Category: Mystery, Thriller & Suspense\n",
      "../data/amz/raw_data/meta_Books.json.gz & 11,906& 17,332 & 133.1& 91.5& 1,585,172& 99.23\\%&5,472&2.0 \\\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_amz.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loading data\n",
      "generating ctr train dataset\n",
      "user num 10715 data num 1265059 pos ratio 0.5997356645026042\n",
      "[[4871, 15, 1], [4871, 16, 0], [4871, 17, 0], [4871, 18, 1], [4871, 19, 0]]\n",
      "generating ctr test dataset\n",
      "user num 1191 data num 141523 pos ratio 0.6047780219469627\n",
      "[[806, 15, 1], [806, 16, 0], [806, 17, 0], [806, 18, 0], [806, 19, 0]]\n",
      "save ctr data\n",
      "generating reranking train dataset\n",
      "user num 10715 data num 320368\n",
      "[[4871, 15, [15997, 1515, 514, 16554, 9561, 4352, 14152, 3177, 10061, 6445], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]], [4871, 19, [6947, 5173, 5843, 6179, 15416, 9008, 3953, 2516, 12550, 13295], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], [4871, 23, [3376, 638, 13477, 11434, 9371, 6416, 6357, 10307, 9379, 7904], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [4871, 27, [771, 7798, 3226, 12614, 17128, 15080, 13346, 2078, 6229, 15281], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], [4871, 31, [1940, 2447, 10316, 14153, 9642, 6721, 4678, 15752, 7417, 10736], [0, 1, 0, 0, 1, 0, 0, 0, 1, 0]]]\n",
      "generating reranking test dataset\n",
      "user num 1191 data num 35834\n",
      "[[806, 15, [7620, 13899, 12687, 15343, 7528, 16521, 13229, 6240, 4704, 3311], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [806, 19, [7624, 2978, 4652, 5135, 517, 6559, 12152, 3349, 1033, 17022], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [806, 23, [13891, 2313, 10375, 3964, 9328, 8933, 6375, 16774, 489, 10452], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [806, 27, [6531, 1038, 4407, 1334, 16234, 12541, 2281, 9126, 14447, 10722], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], [806, 31, [14460, 10371, 12470, 2146, 16098, 6274, 3257, 977, 8331, 4941], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
      "save reranking data\n",
      "generating item prompt\n",
      "data num 17332\n",
      "('0001050230', \"Introduce book Love's Labour's Lost: Performed by Derek Jacobi, Geraldine McEwan & Cast, which is from brand Visit Amazon's William Shakespeare Page and describe its attributes including but not limited to genre, author, writing style, theme, setting, length and complexity, time period, literary quality, critical acclaim.\")\n",
      "generating history prompt\n",
      "item2attribute [('7819', [1, 2]), ('7818', [1, 3]), ('13738', [4, 5]), ('13721', [6, 7]), ('11115', [8, 9]), ('717', [10, 2]), ('13077', [11, 2]), ('7791', [12, 2]), ('9422', [13, 2]), ('6710', [14, 9])]\n",
      "data num 11906\n",
      "('A3U6Y3GD1A6PXJ', 'Given user\\'s book rating history: \"Layers Deep (Layers Trilogy) (Volume 1)\", 5 stars; \"All I Want for Christmas is You\", 5 stars; \"Somebody\\'s Angel (Rescue Me Saga) (Volume 4)\", 5 stars; \"The Lawman Claims His Bride (Charity House)\", 4 stars; \"The Summer He Came Home (Bad Boys of Crystal Lake)\", 4 stars; \"Captured in Surrender: A MacKenzie Family Novella (1001 Dark Nights)\", 5 stars; \"When Day Breaks (A KGI Novel)\", 4 stars; \"Bait: The Angler Series-Book One\", 4 stars; \"Say You Will (The Alexanders) (Volume 5)\", 5 stars; \"Finn (Blue-Collar Billionaires #2) (Volume 2)\", 5 stars; \"No Limits (An Ultimate Novel)\", 5 stars; \"What A Girl Wants (Rock Stars in Disguise: Rhiannon): A New Adult Rock Star Romance (Volume 1)\", 5 stars; \"Scarlett Red: A Billionaire SEAL Story, Part 2 (In the Shadows) (Volume 2)\", 5 stars; \"Shades of Honor (Grayson Brothers) (Volume 1)\", 5 stars; \"Crossed\", 5 stars; Analyze user\\'s preferences on books about factors like genre, author, writing style, theme, setting, length and complexity, time period, literary quality, critical acclaim (Provide clear explanations based on relevant details from the user\\'s book viewing history and other pertinent factors.')\n",
      "save prompt data\n"
     ]
    }
   ],
   "source": [
    "!python generate_data_and_prompt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/knowledge_encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt.hist 1 Given user's book rating history: \"The Pact: A Love Story\", 5 stars; \"Keeping Faith: A Novel (P.S.)\", 5 stars; \"Tiger Lily\", 4 stars; \"Thirteen Reasons Why\", 1 stars; \"The Fault in Our Stars\", 5 stars; \"A False Dawn\", 4 stars; \"My Sister's Keeper\", 5 stars; \"My Sister's Keeper\", 5 stars; \"The BOOK THIEF\", 5 stars; \"Cordina's Royal Family: Bennett & Camilla\", 5 stars; \"Bared to You\", 5 stars; \"Bared to You / Reflected in You / Entwined with You\", 4 stars; \"Hostile Witness\", 1 stars; \"The Gingerbread Man\", 5 stars; \"The Perks Of Being A Wallflower (Turtleback School & Library Binding Edition)\", 5 stars. Based on the user's book rating history, we can make some observations about their preferences:\n",
      "\n",
      "1. Genre: The user seems to enjoy a variety of genres, including romance, young adult fiction, mystery/thriller, and contemporary fiction.\n",
      "\n",
      "2. Author: There is no clear pattern in terms of preferred authors, as the user has rated books by different authors positively.\n",
      "\n",
      "3. Writing style: It appears that the user appreciates books with engaging and well-crafted writing styles, as evidenced by their high ratings for books like \"The Pact: A Love Story\" and \"The Fault in Our Stars.\"\n",
      "\n",
      "4. Theme: The user seems to enjoy books that explore themes of love, family, personal growth, and resilience. This can be seen in their positive ratings for books like \"Keeping Faith: A Novel (P.S.)\" and \"My Sister's Keeper.\"\n",
      "\n",
      "5. Setting: The user's book choices do not show a particular preference for a specific setting. They seem to be open to different settings as long as the story and themes are engaging.\n",
      "\n",
      "6. Length and complexity: The user appears to appreciate books of varying lengths and complexity. They have given high ratings to both shorter novels like \"The Gingerbread Man\" and longer ones like \"The BOOK THIEF.\"\n",
      "\n",
      "7. Time period: The user's book selections do not indicate a strong preference for a specific time period. They seem to enjoy books set in both contemporary and historical periods.\n",
      "\n",
      "8. Literary quality and critical acclaim: The user's ratings suggest that they appreciate books with strong literary quality and critical acclaim. Books like \"The BOOK THIEF\" and \"The Perks Of Being A Wallflower\" have received high praise from critics and have been well-received by readers.\n",
      "\n",
      "Overall, the user's preferences seem to lean towards well-written books with engaging themes and diverse genres. They appreciate both contemporary and historical settings, and are open to different lengths and levels of complexity in their reading choices. hist len 11906\n",
      "chatgpt.item 1 Book Title: North and South\n",
      "\n",
      "Genre: Historical Fiction\n",
      "\n",
      "Author: John Jakes\n",
      "\n",
      "Writing Style: Engaging and descriptive\n",
      "\n",
      "Theme: The divide between the North and South of the United States during the mid-19th century\n",
      "\n",
      "Setting: Primarily set in the United States during the years leading up to and during the Civil War\n",
      "\n",
      "Length and Complexity: A substantial novel of approximately 800 pages, offering a rich and complex storyline\n",
      "\n",
      "Time Period: Mid-19th century, with a focus on the years leading up to and during the Civil War\n",
      "\n",
      "Literary Quality: John Jakes is known for his well-researched historical fiction, and North and South is no exception. The book offers a captivating narrative with well-developed characters and intricate plotlines.\n",
      "\n",
      "Critical Acclaim: North and South has received critical acclaim for its detailed portrayal of the tensions and conflicts between the North and South, as well as its ability to bring historical events to life. The book has been praised for its meticulous research, engaging storytelling, and its ability to capture the essence of the era. With its compelling narrative and well-drawn characters, North and South has become a beloved classic in the genre of historical fiction.\n",
      "\n",
      "To learn more about the book \"North and South\" by John Jakes, visit Amazon's John Jakes Page. item len 17332\n",
      "tokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 399kB/s]\n",
      "config.json: 100%|█████████████████████████████| 570/570 [00:00<00:00, 6.46MB/s]\n",
      "vocab.txt: 100%|██████████████████████████████| 232k/232k [00:00<00:00, 586kB/s]\n",
      "tokenizer.json: 100%|█████████████████████████| 466k/466k [00:00<00:00, 784kB/s]\n",
      "model.safetensors: 100%|██████████████████████| 440M/440M [00:03<00:00, 117MB/s]\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "100%|███████████████████████████████████████| 1084/1084 [00:38<00:00, 28.05it/s]\n",
      "100%|█████████████████████████████████████████| 745/745 [00:27<00:00, 27.56it/s]\n"
     ]
    }
   ],
   "source": [
    "!python lm_encoding.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click-throught rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410231748\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410231748', epoch_num=20, batch_size=256, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50890, train time: 356.92075, test loss: 0.51605, test time: 34.45527, auc: 0.81085, logloss: 0.51599\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48452, train time: 354.93789, test loss: 0.50756, test time: 35.17468, auc: 0.81784, logloss: 0.50750\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.47711, train time: 355.52619, test loss: 0.50469, test time: 34.41656, auc: 0.82001, logloss: 0.50464\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 19768 train loss: 0.47074, train time: 355.52773, test loss: 0.50411, test time: 34.42723, auc: 0.82083, logloss: 0.50406\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 24710 train loss: 0.46586, train time: 355.65315, test loss: 0.50327, test time: 35.14356, auc: 0.82245, logloss: 0.50322\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 29652 train loss: 0.46167, train time: 354.56488, test loss: 0.50905, test time: 34.47026, auc: 0.82120, logloss: 0.50898\n",
      "EPOCH 6  STEP 34594 train loss: 0.45660, train time: 355.57893, test loss: 0.50807, test time: 34.41422, auc: 0.82042, logloss: 0.50802\n",
      "EPOCH 7  STEP 39536 train loss: 0.45073, train time: 355.17704, test loss: 0.50847, test time: 35.27475, auc: 0.82129, logloss: 0.50842\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410231840\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410231840', epoch_num=20, batch_size=256, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50823, train time: 359.07258, test loss: 0.50061, test time: 35.07448, auc: 0.82731, logloss: 0.50056\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48339, train time: 358.43083, test loss: 0.49664, test time: 34.46536, auc: 0.82894, logloss: 0.49658\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.47457, train time: 357.67580, test loss: 0.49438, test time: 35.44316, auc: 0.83061, logloss: 0.49432\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 19768 train loss: 0.46856, train time: 358.88038, test loss: 0.49818, test time: 34.22595, auc: 0.83030, logloss: 0.49813\n",
      "EPOCH 4  STEP 24710 train loss: 0.46388, train time: 358.33346, test loss: 0.49660, test time: 34.52781, auc: 0.82904, logloss: 0.49654\n",
      "EPOCH 5  STEP 29652 train loss: 0.45913, train time: 358.18424, test loss: 0.50028, test time: 34.23670, auc: 0.82597, logloss: 0.50022\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410231920\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410231920', epoch_num=20, batch_size=256, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50828, train time: 365.25280, test loss: 0.50940, test time: 35.14779, auc: 0.81619, logloss: 0.50934\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48340, train time: 365.66286, test loss: 0.50195, test time: 34.42192, auc: 0.82268, logloss: 0.50189\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.47411, train time: 364.76563, test loss: 0.50377, test time: 35.17399, auc: 0.82179, logloss: 0.50372\n",
      "EPOCH 3  STEP 19768 train loss: 0.46796, train time: 365.38940, test loss: 0.50410, test time: 34.44091, auc: 0.82245, logloss: 0.50404\n",
      "EPOCH 4  STEP 24710 train loss: 0.46249, train time: 365.55202, test loss: 0.51186, test time: 34.40996, auc: 0.82171, logloss: 0.51181\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410231953\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410231953', epoch_num=20, batch_size=256, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50759, train time: 372.85411, test loss: 0.49858, test time: 35.61680, auc: 0.82548, logloss: 0.49852\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48330, train time: 372.53179, test loss: 0.49628, test time: 35.57429, auc: 0.82749, logloss: 0.49622\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.47409, train time: 373.23121, test loss: 0.49551, test time: 34.68040, auc: 0.82849, logloss: 0.49546\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 19768 train loss: 0.46713, train time: 373.41047, test loss: 0.49736, test time: 36.16922, auc: 0.82655, logloss: 0.49731\n",
      "EPOCH 4  STEP 24710 train loss: 0.46057, train time: 373.35895, test loss: 0.50641, test time: 34.83146, auc: 0.82473, logloss: 0.50634\n",
      "EPOCH 5  STEP 29652 train loss: 0.45333, train time: 373.36711, test loss: 0.50208, test time: 34.82891, auc: 0.82451, logloss: 0.50202\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232035\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232035', epoch_num=20, batch_size=256, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50787, train time: 377.24233, test loss: 0.51360, test time: 34.60998, auc: 0.81241, logloss: 0.51355\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48446, train time: 375.34474, test loss: 0.50776, test time: 35.44323, auc: 0.81764, logloss: 0.50770\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.47475, train time: 376.06729, test loss: 0.50558, test time: 34.72823, auc: 0.82032, logloss: 0.50552\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 19768 train loss: 0.46683, train time: 376.13426, test loss: 0.50457, test time: 35.27210, auc: 0.82170, logloss: 0.50450\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 24710 train loss: 0.45982, train time: 378.25097, test loss: 0.50698, test time: 35.29313, auc: 0.82238, logloss: 0.50691\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 29652 train loss: 0.45358, train time: 376.96261, test loss: 0.50780, test time: 35.65474, auc: 0.82055, logloss: 0.50774\n",
      "EPOCH 6  STEP 34594 train loss: 0.44734, train time: 375.16301, test loss: 0.51210, test time: 35.58700, auc: 0.82080, logloss: 0.51203\n",
      "EPOCH 7  STEP 39536 train loss: 0.44100, train time: 375.92268, test loss: 0.51095, test time: 35.47918, auc: 0.81978, logloss: 0.51088\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 5e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232130\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232130', epoch_num=20, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50470, train time: 354.61289, test loss: 0.49669, test time: 34.11460, auc: 0.82693, logloss: 0.49663\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48162, train time: 352.12456, test loss: 0.49455, test time: 34.78435, auc: 0.82934, logloss: 0.49449\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46649, train time: 352.05738, test loss: 0.49466, test time: 33.99478, auc: 0.83036, logloss: 0.49459\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 19768 train loss: 0.44978, train time: 351.70921, test loss: 0.50189, test time: 33.91534, auc: 0.82647, logloss: 0.50184\n",
      "EPOCH 4  STEP 24710 train loss: 0.43191, train time: 350.84908, test loss: 0.51599, test time: 34.53811, auc: 0.82057, logloss: 0.51594\n",
      "EPOCH 5  STEP 29652 train loss: 0.41325, train time: 348.86806, test loss: 0.54100, test time: 33.95299, auc: 0.81514, logloss: 0.54094\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 5e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232209\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232209', epoch_num=20, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50311, train time: 367.95917, test loss: 0.50105, test time: 36.00043, auc: 0.82918, logloss: 0.50100\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47910, train time: 368.02985, test loss: 0.49068, test time: 35.10909, auc: 0.83264, logloss: 0.49062\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46067, train time: 367.72275, test loss: 0.49283, test time: 36.01197, auc: 0.83150, logloss: 0.49278\n",
      "EPOCH 3  STEP 19768 train loss: 0.44244, train time: 368.35814, test loss: 0.51454, test time: 35.24844, auc: 0.82527, logloss: 0.51448\n",
      "EPOCH 4  STEP 24710 train loss: 0.42312, train time: 368.28526, test loss: 0.52555, test time: 35.21701, auc: 0.82002, logloss: 0.52549\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 5e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232243\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232243', epoch_num=20, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50347, train time: 366.52655, test loss: 0.49799, test time: 35.37424, auc: 0.82577, logloss: 0.49793\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47869, train time: 365.34427, test loss: 0.49453, test time: 34.85554, auc: 0.82869, logloss: 0.49446\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46064, train time: 364.51072, test loss: 0.50056, test time: 35.54970, auc: 0.82569, logloss: 0.50051\n",
      "EPOCH 3  STEP 19768 train loss: 0.44342, train time: 364.40558, test loss: 0.51068, test time: 34.34423, auc: 0.82033, logloss: 0.51062\n",
      "EPOCH 4  STEP 24710 train loss: 0.42533, train time: 363.83086, test loss: 0.53078, test time: 34.27275, auc: 0.81548, logloss: 0.53074\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 5e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232316\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232316', epoch_num=20, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50332, train time: 372.08649, test loss: 0.49185, test time: 36.18836, auc: 0.83098, logloss: 0.49179\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47884, train time: 372.03667, test loss: 0.48756, test time: 35.36641, auc: 0.83534, logloss: 0.48750\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46186, train time: 374.05665, test loss: 0.49228, test time: 35.15682, auc: 0.83196, logloss: 0.49223\n",
      "EPOCH 3  STEP 19768 train loss: 0.44296, train time: 374.16183, test loss: 0.50088, test time: 34.57251, auc: 0.82819, logloss: 0.50082\n",
      "EPOCH 4  STEP 24710 train loss: 0.42249, train time: 371.18673, test loss: 0.53528, test time: 35.38634, auc: 0.81795, logloss: 0.53519\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 5e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410232351\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410232351', epoch_num=20, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50360, train time: 378.75883, test loss: 0.49940, test time: 34.86220, auc: 0.82630, logloss: 0.49935\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.48003, train time: 378.86446, test loss: 0.49209, test time: 35.71621, auc: 0.83101, logloss: 0.49204\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46270, train time: 379.91419, test loss: 0.49654, test time: 35.44393, auc: 0.82989, logloss: 0.49649\n",
      "EPOCH 3  STEP 19768 train loss: 0.44616, train time: 378.50515, test loss: 0.49980, test time: 34.79969, auc: 0.82629, logloss: 0.49974\n",
      "EPOCH 4  STEP 24710 train loss: 0.42829, train time: 378.51030, test loss: 0.51671, test time: 34.96818, auc: 0.81998, logloss: 0.51665\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-3 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240025\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240025', epoch_num=20, batch_size=256, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50422, train time: 356.61527, test loss: 0.49431, test time: 34.34216, auc: 0.83033, logloss: 0.49425\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47912, train time: 354.39970, test loss: 0.48787, test time: 35.06387, auc: 0.83420, logloss: 0.48781\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.46000, train time: 355.19467, test loss: 0.49571, test time: 34.35055, auc: 0.83102, logloss: 0.49566\n",
      "EPOCH 3  STEP 19768 train loss: 0.43926, train time: 355.12961, test loss: 0.50374, test time: 34.34280, auc: 0.82625, logloss: 0.50370\n",
      "EPOCH 4  STEP 24710 train loss: 0.41647, train time: 355.13724, test loss: 0.52688, test time: 35.04295, auc: 0.81625, logloss: 0.52684\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-3 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240058\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240058', epoch_num=20, batch_size=256, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50336, train time: 363.60460, test loss: 0.49079, test time: 36.14496, auc: 0.83283, logloss: 0.49073\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47840, train time: 362.50170, test loss: 0.49079, test time: 35.02315, auc: 0.83352, logloss: 0.49073\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.45808, train time: 361.82154, test loss: 0.49280, test time: 35.24892, auc: 0.83123, logloss: 0.49275\n",
      "EPOCH 3  STEP 19768 train loss: 0.43605, train time: 363.20615, test loss: 0.51390, test time: 35.00346, auc: 0.82466, logloss: 0.51385\n",
      "EPOCH 4  STEP 24710 train loss: 0.41223, train time: 360.82197, test loss: 0.54049, test time: 34.36144, auc: 0.81616, logloss: 0.54044\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-3 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240132\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240132', epoch_num=20, batch_size=256, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50323, train time: 363.60067, test loss: 0.49187, test time: 35.18498, auc: 0.83103, logloss: 0.49180\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47782, train time: 361.93830, test loss: 0.48964, test time: 34.30357, auc: 0.83251, logloss: 0.48958\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.45801, train time: 360.60006, test loss: 0.49606, test time: 34.92246, auc: 0.82986, logloss: 0.49600\n",
      "EPOCH 3  STEP 19768 train loss: 0.43714, train time: 360.53208, test loss: 0.50939, test time: 34.23635, auc: 0.82317, logloss: 0.50934\n",
      "EPOCH 4  STEP 24710 train loss: 0.41325, train time: 359.24863, test loss: 0.53961, test time: 34.23137, auc: 0.81577, logloss: 0.53957\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-3 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240205\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240205', epoch_num=20, batch_size=256, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50387, train time: 378.14078, test loss: 0.49089, test time: 36.34374, auc: 0.83243, logloss: 0.49083\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47839, train time: 377.84574, test loss: 0.48697, test time: 36.60294, auc: 0.83526, logloss: 0.48691\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.45882, train time: 376.78312, test loss: 0.49445, test time: 35.39814, auc: 0.83150, logloss: 0.49440\n",
      "EPOCH 3  STEP 19768 train loss: 0.43817, train time: 377.23541, test loss: 0.50574, test time: 35.36871, auc: 0.82645, logloss: 0.50569\n",
      "EPOCH 4  STEP 24710 train loss: 0.41454, train time: 375.68086, test loss: 0.53385, test time: 35.88477, auc: 0.81800, logloss: 0.53378\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 256 1e-3 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240240\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240240', epoch_num=20, batch_size=256, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 4942 train loss: 0.50380, train time: 380.38489, test loss: 0.49688, test time: 35.00068, auc: 0.82886, logloss: 0.49683\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 9884 train loss: 0.47898, train time: 378.58563, test loss: 0.49098, test time: 35.80894, auc: 0.83193, logloss: 0.49092\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs256_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 14826 train loss: 0.45938, train time: 379.09208, test loss: 0.49856, test time: 34.97918, auc: 0.82994, logloss: 0.49850\n",
      "EPOCH 3  STEP 19768 train loss: 0.43855, train time: 379.47515, test loss: 0.50361, test time: 35.59094, auc: 0.82487, logloss: 0.50354\n",
      "EPOCH 4  STEP 24710 train loss: 0.41475, train time: 380.23105, test loss: 0.53358, test time: 35.03004, auc: 0.81463, logloss: 0.53366\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240314\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240314', epoch_num=20, batch_size=512, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.51230, train time: 336.11266, test loss: 0.51249, test time: 34.89060, auc: 0.81361, logloss: 0.51212\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48481, train time: 336.91758, test loss: 0.50763, test time: 34.20619, auc: 0.81933, logloss: 0.50723\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47809, train time: 336.81792, test loss: 0.50446, test time: 34.25372, auc: 0.82080, logloss: 0.50406\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 9884 train loss: 0.47220, train time: 335.44406, test loss: 0.50601, test time: 34.93918, auc: 0.81918, logloss: 0.50563\n",
      "EPOCH 4  STEP 12355 train loss: 0.46739, train time: 335.35229, test loss: 0.50373, test time: 34.25213, auc: 0.82166, logloss: 0.50335\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 14826 train loss: 0.46372, train time: 336.58523, test loss: 0.50710, test time: 34.20725, auc: 0.82132, logloss: 0.50670\n",
      "EPOCH 6  STEP 17297 train loss: 0.46067, train time: 335.36024, test loss: 0.50457, test time: 34.89754, auc: 0.82206, logloss: 0.50420\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 7  STEP 19768 train loss: 0.45759, train time: 335.74111, test loss: 0.50872, test time: 34.90036, auc: 0.82185, logloss: 0.50835\n",
      "EPOCH 8  STEP 22239 train loss: 0.45358, train time: 335.68133, test loss: 0.51515, test time: 34.27878, auc: 0.81885, logloss: 0.51473\n",
      "EPOCH 9  STEP 24710 train loss: 0.44873, train time: 335.59830, test loss: 0.51326, test time: 34.19253, auc: 0.81934, logloss: 0.51284\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240417\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240417', epoch_num=20, batch_size=512, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.51147, train time: 343.72724, test loss: 0.49675, test time: 34.63781, auc: 0.82744, logloss: 0.49638\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48406, train time: 343.40499, test loss: 0.49485, test time: 34.62226, auc: 0.83013, logloss: 0.49452\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47551, train time: 343.16809, test loss: 0.49523, test time: 35.31479, auc: 0.82971, logloss: 0.49489\n",
      "EPOCH 3  STEP 9884 train loss: 0.46957, train time: 342.37273, test loss: 0.49569, test time: 36.06856, auc: 0.83013, logloss: 0.49529\n",
      "EPOCH 4  STEP 12355 train loss: 0.46542, train time: 342.10190, test loss: 0.49735, test time: 35.35462, auc: 0.82967, logloss: 0.49697\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240448\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240448', epoch_num=20, batch_size=512, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.51177, train time: 343.98563, test loss: 0.50810, test time: 34.50787, auc: 0.81793, logloss: 0.50770\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48460, train time: 343.33482, test loss: 0.50669, test time: 34.52189, auc: 0.81981, logloss: 0.50628\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47608, train time: 344.69904, test loss: 0.50479, test time: 34.52344, auc: 0.82075, logloss: 0.50443\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 9884 train loss: 0.46960, train time: 344.17162, test loss: 0.50753, test time: 35.06420, auc: 0.81981, logloss: 0.50712\n",
      "EPOCH 4  STEP 12355 train loss: 0.46490, train time: 341.95565, test loss: 0.50616, test time: 34.92170, auc: 0.82132, logloss: 0.50583\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 14826 train loss: 0.46070, train time: 341.60304, test loss: 0.50658, test time: 34.25972, auc: 0.82104, logloss: 0.50620\n",
      "EPOCH 6  STEP 17297 train loss: 0.45605, train time: 340.54122, test loss: 0.50990, test time: 34.44129, auc: 0.82027, logloss: 0.50950\n",
      "EPOCH 7  STEP 19768 train loss: 0.45091, train time: 340.06054, test loss: 0.51252, test time: 34.28577, auc: 0.82006, logloss: 0.51218\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240539\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240539', epoch_num=20, batch_size=512, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.51050, train time: 347.53700, test loss: 0.50342, test time: 34.45444, auc: 0.82487, logloss: 0.50307\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48388, train time: 346.25580, test loss: 0.49766, test time: 35.14437, auc: 0.82686, logloss: 0.49727\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47534, train time: 344.09758, test loss: 0.49596, test time: 34.32880, auc: 0.82832, logloss: 0.49556\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 9884 train loss: 0.46859, train time: 342.44067, test loss: 0.49757, test time: 34.18992, auc: 0.82671, logloss: 0.49719\n",
      "EPOCH 4  STEP 12355 train loss: 0.46294, train time: 343.06881, test loss: 0.50293, test time: 34.73213, auc: 0.82426, logloss: 0.50251\n",
      "EPOCH 5  STEP 14826 train loss: 0.45724, train time: 339.98727, test loss: 0.50227, test time: 34.18864, auc: 0.82440, logloss: 0.50189\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240617\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240617', epoch_num=20, batch_size=512, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.51053, train time: 349.97472, test loss: 0.51511, test time: 34.63615, auc: 0.81827, logloss: 0.51480\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48536, train time: 348.46684, test loss: 0.50487, test time: 34.69498, auc: 0.82088, logloss: 0.50449\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47670, train time: 348.91405, test loss: 0.50585, test time: 35.09326, auc: 0.82205, logloss: 0.50544\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 9884 train loss: 0.46985, train time: 348.57598, test loss: 0.50299, test time: 35.27136, auc: 0.82213, logloss: 0.50258\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 12355 train loss: 0.46464, train time: 348.89249, test loss: 0.50726, test time: 35.51014, auc: 0.82182, logloss: 0.50682\n",
      "EPOCH 5  STEP 14826 train loss: 0.45945, train time: 349.47947, test loss: 0.50639, test time: 35.38189, auc: 0.82048, logloss: 0.50599\n",
      "EPOCH 6  STEP 17297 train loss: 0.45413, train time: 348.75675, test loss: 0.51247, test time: 35.28389, auc: 0.82067, logloss: 0.51195\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 5e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240702\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240702', epoch_num=20, batch_size=512, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50528, train time: 338.18110, test loss: 0.49893, test time: 34.46075, auc: 0.82633, logloss: 0.49852\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48214, train time: 336.81291, test loss: 0.49962, test time: 34.37728, auc: 0.82866, logloss: 0.49918\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.47005, train time: 336.71211, test loss: 0.49533, test time: 34.38249, auc: 0.82903, logloss: 0.49495\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 9884 train loss: 0.45633, train time: 336.77468, test loss: 0.49897, test time: 35.15942, auc: 0.82685, logloss: 0.49862\n",
      "EPOCH 4  STEP 12355 train loss: 0.44211, train time: 336.68450, test loss: 0.50757, test time: 34.43266, auc: 0.82317, logloss: 0.50718\n",
      "EPOCH 5  STEP 14826 train loss: 0.42662, train time: 336.48835, test loss: 0.52512, test time: 34.47733, auc: 0.81775, logloss: 0.52466\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 5e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240740\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240740', epoch_num=20, batch_size=512, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50425, train time: 340.65622, test loss: 0.49405, test time: 35.25496, auc: 0.82973, logloss: 0.49368\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48086, train time: 340.84391, test loss: 0.49095, test time: 35.24573, auc: 0.83294, logloss: 0.49060\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46594, train time: 342.06786, test loss: 0.49336, test time: 34.39395, auc: 0.83171, logloss: 0.49300\n",
      "EPOCH 3  STEP 9884 train loss: 0.44916, train time: 339.35947, test loss: 0.50928, test time: 35.95456, auc: 0.82728, logloss: 0.50891\n",
      "EPOCH 4  STEP 12355 train loss: 0.43122, train time: 340.59106, test loss: 0.52013, test time: 35.19550, auc: 0.82185, logloss: 0.51973\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 5e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240811\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240811', epoch_num=20, batch_size=512, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50460, train time: 343.24341, test loss: 0.49696, test time: 34.41747, auc: 0.82741, logloss: 0.49659\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48051, train time: 342.63624, test loss: 0.49373, test time: 35.09617, auc: 0.82984, logloss: 0.49333\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46511, train time: 343.80082, test loss: 0.49545, test time: 34.46623, auc: 0.82961, logloss: 0.49507\n",
      "EPOCH 3  STEP 9884 train loss: 0.44958, train time: 343.85032, test loss: 0.50262, test time: 35.10249, auc: 0.82563, logloss: 0.50225\n",
      "EPOCH 4  STEP 12355 train loss: 0.43403, train time: 343.76540, test loss: 0.51450, test time: 35.16382, auc: 0.82073, logloss: 0.51416\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 5e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240843\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240843', epoch_num=20, batch_size=512, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50384, train time: 344.25532, test loss: 0.49897, test time: 34.52227, auc: 0.82972, logloss: 0.49860\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48092, train time: 342.88556, test loss: 0.48935, test time: 34.47553, auc: 0.83332, logloss: 0.48892\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46654, train time: 342.93232, test loss: 0.49077, test time: 34.48243, auc: 0.83253, logloss: 0.49036\n",
      "EPOCH 3  STEP 9884 train loss: 0.45086, train time: 342.76563, test loss: 0.49932, test time: 34.47031, auc: 0.82832, logloss: 0.49896\n",
      "EPOCH 4  STEP 12355 train loss: 0.43294, train time: 342.78990, test loss: 0.52004, test time: 35.26254, auc: 0.82043, logloss: 0.51959\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 5e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240915\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240915', epoch_num=20, batch_size=512, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50381, train time: 350.07319, test loss: 0.50087, test time: 34.67190, auc: 0.82647, logloss: 0.50052\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48118, train time: 348.51117, test loss: 0.49395, test time: 34.71766, auc: 0.82944, logloss: 0.49354\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46720, train time: 348.56056, test loss: 0.49617, test time: 34.71377, auc: 0.82898, logloss: 0.49575\n",
      "EPOCH 3  STEP 9884 train loss: 0.45257, train time: 348.79026, test loss: 0.49862, test time: 34.72618, auc: 0.82657, logloss: 0.49823\n",
      "EPOCH 4  STEP 12355 train loss: 0.43670, train time: 348.99509, test loss: 0.51472, test time: 35.38143, auc: 0.81977, logloss: 0.51435\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-3 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410240947\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410240947', epoch_num=20, batch_size=512, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50483, train time: 341.74038, test loss: 0.49738, test time: 34.75735, auc: 0.82861, logloss: 0.49698\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48090, train time: 341.48082, test loss: 0.49763, test time: 35.39472, auc: 0.83177, logloss: 0.49717\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46402, train time: 340.86364, test loss: 0.49467, test time: 34.69253, auc: 0.82993, logloss: 0.49427\n",
      "EPOCH 3  STEP 9884 train loss: 0.44486, train time: 340.73471, test loss: 0.50344, test time: 35.48961, auc: 0.82520, logloss: 0.50310\n",
      "EPOCH 4  STEP 12355 train loss: 0.42420, train time: 340.34219, test loss: 0.52288, test time: 34.85433, auc: 0.81749, logloss: 0.52249\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-3 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241019\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241019', epoch_num=20, batch_size=512, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50400, train time: 337.50820, test loss: 0.49221, test time: 35.18644, auc: 0.83132, logloss: 0.49184\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.47983, train time: 337.51350, test loss: 0.48929, test time: 34.36977, auc: 0.83462, logloss: 0.48894\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46128, train time: 339.44498, test loss: 0.49394, test time: 34.34187, auc: 0.83203, logloss: 0.49359\n",
      "EPOCH 3  STEP 9884 train loss: 0.44074, train time: 335.97391, test loss: 0.51501, test time: 34.99720, auc: 0.82579, logloss: 0.51463\n",
      "EPOCH 4  STEP 12355 train loss: 0.41861, train time: 336.04943, test loss: 0.53089, test time: 34.31017, auc: 0.81870, logloss: 0.53055\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-3 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241050\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241050', epoch_num=20, batch_size=512, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50364, train time: 342.24866, test loss: 0.49390, test time: 34.35807, auc: 0.82989, logloss: 0.49352\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.47887, train time: 341.29457, test loss: 0.48956, test time: 34.32193, auc: 0.83318, logloss: 0.48910\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.45923, train time: 341.06689, test loss: 0.49434, test time: 34.37517, auc: 0.83093, logloss: 0.49395\n",
      "EPOCH 3  STEP 9884 train loss: 0.43935, train time: 341.04919, test loss: 0.50724, test time: 35.10963, auc: 0.82495, logloss: 0.50684\n",
      "EPOCH 4  STEP 12355 train loss: 0.41729, train time: 339.52770, test loss: 0.53024, test time: 34.38411, auc: 0.81614, logloss: 0.52990\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-3 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241122\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241122', epoch_num=20, batch_size=512, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50361, train time: 347.02966, test loss: 0.49149, test time: 34.63020, auc: 0.83348, logloss: 0.49111\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.47896, train time: 345.54390, test loss: 0.48568, test time: 34.60036, auc: 0.83600, logloss: 0.48526\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46142, train time: 345.31254, test loss: 0.49150, test time: 34.62267, auc: 0.83236, logloss: 0.49109\n",
      "EPOCH 3  STEP 9884 train loss: 0.44061, train time: 345.50990, test loss: 0.50156, test time: 35.62416, auc: 0.82734, logloss: 0.50122\n",
      "EPOCH 4  STEP 12355 train loss: 0.41777, train time: 346.87944, test loss: 0.52916, test time: 35.34116, auc: 0.81934, logloss: 0.52873\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 512 1e-3 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241154\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241154', epoch_num=20, batch_size=512, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 2471 train loss: 0.50368, train time: 348.18884, test loss: 0.49843, test time: 35.44910, auc: 0.82895, logloss: 0.49809\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 4942 train loss: 0.48019, train time: 350.09855, test loss: 0.49073, test time: 34.55092, auc: 0.83203, logloss: 0.49032\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs512_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 7413 train loss: 0.46271, train time: 346.77439, test loss: 0.49499, test time: 35.45692, auc: 0.83042, logloss: 0.49457\n",
      "EPOCH 3  STEP 9884 train loss: 0.44291, train time: 348.30434, test loss: 0.50344, test time: 35.54735, auc: 0.82428, logloss: 0.50302\n",
      "EPOCH 4  STEP 12355 train loss: 0.42148, train time: 348.30630, test loss: 0.52707, test time: 35.91860, auc: 0.81602, logloss: 0.52670\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241226\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241226', epoch_num=20, batch_size=2048, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.52894, train time: 329.38844, test loss: 0.50833, test time: 37.32593, auc: 0.81979, logloss: 0.50600\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48825, train time: 328.37208, test loss: 0.50349, test time: 37.53040, auc: 0.82420, logloss: 0.50110\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.48066, train time: 331.52108, test loss: 0.50204, test time: 36.37483, auc: 0.82470, logloss: 0.49964\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 2472 train loss: 0.47655, train time: 329.28010, test loss: 0.50308, test time: 35.51227, auc: 0.82456, logloss: 0.50095\n",
      "EPOCH 4  STEP 3090 train loss: 0.47295, train time: 331.26153, test loss: 0.50191, test time: 34.92867, auc: 0.82474, logloss: 0.49960\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 3708 train loss: 0.46956, train time: 327.26208, test loss: 0.50646, test time: 35.61001, auc: 0.82442, logloss: 0.50412\n",
      "EPOCH 6  STEP 4326 train loss: 0.46590, train time: 327.14874, test loss: 0.50665, test time: 34.93153, auc: 0.82401, logloss: 0.50450\n",
      "EPOCH 7  STEP 4944 train loss: 0.46309, train time: 327.11642, test loss: 0.50702, test time: 35.66969, auc: 0.82228, logloss: 0.50454\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241315\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241315', epoch_num=20, batch_size=2048, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.52671, train time: 329.68540, test loss: 0.50091, test time: 34.73893, auc: 0.82576, logloss: 0.49872\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48721, train time: 331.57131, test loss: 0.49718, test time: 35.45881, auc: 0.82869, logloss: 0.49483\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47857, train time: 327.73617, test loss: 0.49673, test time: 36.10884, auc: 0.82950, logloss: 0.49431\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 2472 train loss: 0.47281, train time: 331.90754, test loss: 0.49829, test time: 37.22626, auc: 0.82847, logloss: 0.49592\n",
      "EPOCH 4  STEP 3090 train loss: 0.46809, train time: 329.59235, test loss: 0.49934, test time: 36.80634, auc: 0.82800, logloss: 0.49705\n",
      "EPOCH 5  STEP 3708 train loss: 0.46504, train time: 327.09165, test loss: 0.50336, test time: 36.64529, auc: 0.82782, logloss: 0.50100\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241352\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241352', epoch_num=20, batch_size=2048, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.52812, train time: 332.05681, test loss: 0.50444, test time: 35.01520, auc: 0.82286, logloss: 0.50206\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48699, train time: 332.63667, test loss: 0.50200, test time: 36.70274, auc: 0.82531, logloss: 0.49938\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47953, train time: 330.24081, test loss: 0.50261, test time: 34.79345, auc: 0.82495, logloss: 0.49999\n",
      "EPOCH 3  STEP 2472 train loss: 0.47383, train time: 328.02947, test loss: 0.50450, test time: 35.20574, auc: 0.82267, logloss: 0.50208\n",
      "EPOCH 4  STEP 3090 train loss: 0.46900, train time: 327.56609, test loss: 0.50926, test time: 34.47517, auc: 0.82325, logloss: 0.50720\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241423\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241423', epoch_num=20, batch_size=2048, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.52427, train time: 333.02745, test loss: 0.50307, test time: 35.00534, auc: 0.82503, logloss: 0.50077\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48668, train time: 330.26892, test loss: 0.49739, test time: 35.34675, auc: 0.82911, logloss: 0.49490\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47882, train time: 329.46243, test loss: 0.49694, test time: 34.74079, auc: 0.82873, logloss: 0.49480\n",
      "EPOCH 3  STEP 2472 train loss: 0.47321, train time: 328.75789, test loss: 0.49785, test time: 35.32793, auc: 0.82898, logloss: 0.49559\n",
      "EPOCH 4  STEP 3090 train loss: 0.46827, train time: 328.54642, test loss: 0.50108, test time: 34.78889, auc: 0.82668, logloss: 0.49852\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241453\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241453', epoch_num=20, batch_size=2048, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.52508, train time: 337.02768, test loss: 0.50505, test time: 36.44254, auc: 0.82280, logloss: 0.50274\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48804, train time: 336.03282, test loss: 0.50045, test time: 36.01657, auc: 0.82588, logloss: 0.49816\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.48083, train time: 333.84992, test loss: 0.50036, test time: 35.06323, auc: 0.82622, logloss: 0.49811\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 2472 train loss: 0.47530, train time: 335.17907, test loss: 0.50267, test time: 35.65300, auc: 0.82583, logloss: 0.50016\n",
      "EPOCH 4  STEP 3090 train loss: 0.47038, train time: 331.93099, test loss: 0.50204, test time: 35.82426, auc: 0.82562, logloss: 0.49968\n",
      "EPOCH 5  STEP 3708 train loss: 0.46620, train time: 331.15831, test loss: 0.50385, test time: 35.58331, auc: 0.82524, logloss: 0.50147\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 5e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241531\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241531', epoch_num=20, batch_size=2048, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.51023, train time: 326.67499, test loss: 0.50196, test time: 35.31502, auc: 0.82727, logloss: 0.49990\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48400, train time: 325.18790, test loss: 0.49969, test time: 35.44317, auc: 0.82942, logloss: 0.49718\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47530, train time: 325.77290, test loss: 0.50094, test time: 34.77513, auc: 0.82894, logloss: 0.49821\n",
      "EPOCH 3  STEP 2472 train loss: 0.46788, train time: 325.85313, test loss: 0.49886, test time: 35.31445, auc: 0.82857, logloss: 0.49656\n",
      "EPOCH 4  STEP 3090 train loss: 0.46005, train time: 327.51225, test loss: 0.49990, test time: 34.77515, auc: 0.82787, logloss: 0.49758\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 5e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241601\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241601', epoch_num=20, batch_size=2048, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50895, train time: 329.03761, test loss: 0.49716, test time: 34.74550, auc: 0.82965, logloss: 0.49496\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48274, train time: 326.95374, test loss: 0.49619, test time: 35.50820, auc: 0.83144, logloss: 0.49367\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47257, train time: 327.00868, test loss: 0.49696, test time: 34.88271, auc: 0.83124, logloss: 0.49429\n",
      "EPOCH 3  STEP 2472 train loss: 0.46344, train time: 326.98069, test loss: 0.50320, test time: 35.49183, auc: 0.83009, logloss: 0.50101\n",
      "EPOCH 4  STEP 3090 train loss: 0.45394, train time: 327.05511, test loss: 0.50176, test time: 34.91551, auc: 0.82790, logloss: 0.49933\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 5e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241631\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241631', epoch_num=20, batch_size=2048, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50980, train time: 329.88035, test loss: 0.49922, test time: 34.83596, auc: 0.82812, logloss: 0.49708\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48302, train time: 328.02509, test loss: 0.49783, test time: 37.25142, auc: 0.82998, logloss: 0.49512\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47263, train time: 331.85644, test loss: 0.49818, test time: 34.80245, auc: 0.82977, logloss: 0.49595\n",
      "EPOCH 3  STEP 2472 train loss: 0.46372, train time: 328.18244, test loss: 0.50129, test time: 35.41072, auc: 0.82887, logloss: 0.49839\n",
      "EPOCH 4  STEP 3090 train loss: 0.45506, train time: 328.07529, test loss: 0.50850, test time: 34.89354, auc: 0.82618, logloss: 0.50654\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 5e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241702\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241702', epoch_num=20, batch_size=2048, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50810, train time: 337.30841, test loss: 0.49675, test time: 35.29412, auc: 0.82982, logloss: 0.49418\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48243, train time: 338.54401, test loss: 0.49246, test time: 35.99394, auc: 0.83211, logloss: 0.49003\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47237, train time: 334.80207, test loss: 0.49555, test time: 35.37759, auc: 0.83110, logloss: 0.49298\n",
      "EPOCH 3  STEP 2472 train loss: 0.46354, train time: 334.90550, test loss: 0.49693, test time: 36.00741, auc: 0.83038, logloss: 0.49474\n",
      "EPOCH 4  STEP 3090 train loss: 0.45215, train time: 334.97772, test loss: 0.50902, test time: 35.34510, auc: 0.82712, logloss: 0.50661\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 5e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241733\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241733', epoch_num=20, batch_size=2048, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50886, train time: 329.36168, test loss: 0.49763, test time: 34.78981, auc: 0.82803, logloss: 0.49535\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48308, train time: 328.48728, test loss: 0.49462, test time: 35.45599, auc: 0.83036, logloss: 0.49229\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47179, train time: 328.59926, test loss: 0.49746, test time: 34.83768, auc: 0.82981, logloss: 0.49493\n",
      "EPOCH 3  STEP 2472 train loss: 0.46204, train time: 328.67618, test loss: 0.50388, test time: 35.43468, auc: 0.82724, logloss: 0.50115\n",
      "EPOCH 4  STEP 3090 train loss: 0.45218, train time: 329.80990, test loss: 0.50541, test time: 35.42646, auc: 0.82552, logloss: 0.50304\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-3 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241804\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241804', epoch_num=20, batch_size=2048, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50785, train time: 331.66014, test loss: 0.50293, test time: 35.54888, auc: 0.82854, logloss: 0.50093\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48313, train time: 328.73243, test loss: 0.49452, test time: 35.56805, auc: 0.83079, logloss: 0.49222\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.47213, train time: 328.34194, test loss: 0.50240, test time: 34.68703, auc: 0.83029, logloss: 0.49982\n",
      "EPOCH 3  STEP 2472 train loss: 0.45935, train time: 327.78530, test loss: 0.49923, test time: 35.19752, auc: 0.82796, logloss: 0.49691\n",
      "EPOCH 4  STEP 3090 train loss: 0.44563, train time: 326.88624, test loss: 0.50695, test time: 34.67980, auc: 0.82510, logloss: 0.50446\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-3 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241835\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241835', epoch_num=20, batch_size=2048, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50667, train time: 330.50924, test loss: 0.49411, test time: 34.73888, auc: 0.83104, logloss: 0.49181\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48151, train time: 329.08151, test loss: 0.49230, test time: 35.32973, auc: 0.83338, logloss: 0.48984\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.46788, train time: 328.34627, test loss: 0.49444, test time: 34.58394, auc: 0.83250, logloss: 0.49188\n",
      "EPOCH 3  STEP 2472 train loss: 0.45272, train time: 327.51737, test loss: 0.50749, test time: 35.10735, auc: 0.82953, logloss: 0.50537\n",
      "EPOCH 4  STEP 3090 train loss: 0.43584, train time: 327.11382, test loss: 0.51612, test time: 34.55214, auc: 0.82338, logloss: 0.51412\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-3 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241905\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241905', epoch_num=20, batch_size=2048, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50691, train time: 338.63033, test loss: 0.49965, test time: 35.67742, auc: 0.82950, logloss: 0.49762\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48155, train time: 337.02400, test loss: 0.49723, test time: 36.29250, auc: 0.83140, logloss: 0.49443\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.46836, train time: 336.14749, test loss: 0.49627, test time: 35.69388, auc: 0.83136, logloss: 0.49405\n",
      "EPOCH 3  STEP 2472 train loss: 0.45371, train time: 335.48444, test loss: 0.50217, test time: 36.08914, auc: 0.82888, logloss: 0.49990\n",
      "EPOCH 4  STEP 3090 train loss: 0.43846, train time: 334.86132, test loss: 0.51657, test time: 35.38558, auc: 0.82463, logloss: 0.51488\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-3 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410241937\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410241937', epoch_num=20, batch_size=2048, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50590, train time: 331.79942, test loss: 0.49565, test time: 34.84281, auc: 0.83121, logloss: 0.49306\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48146, train time: 329.29959, test loss: 0.48925, test time: 35.47299, auc: 0.83466, logloss: 0.48666\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.46751, train time: 328.39719, test loss: 0.49485, test time: 34.59488, auc: 0.83361, logloss: 0.49204\n",
      "EPOCH 3  STEP 2472 train loss: 0.45332, train time: 328.39549, test loss: 0.49793, test time: 35.29001, auc: 0.83037, logloss: 0.49531\n",
      "EPOCH 4  STEP 3090 train loss: 0.43730, train time: 328.08981, test loss: 0.51822, test time: 34.73868, auc: 0.82434, logloss: 0.51552\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 2048 1e-3 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410242007\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410242007', epoch_num=20, batch_size=2048, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 618 train loss: 0.50695, train time: 331.59621, test loss: 0.49714, test time: 34.85202, auc: 0.82959, logloss: 0.49494\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 1236 train loss: 0.48164, train time: 332.47457, test loss: 0.49226, test time: 35.40666, auc: 0.83293, logloss: 0.48965\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs2048_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 1854 train loss: 0.46705, train time: 330.72608, test loss: 0.49693, test time: 34.90950, auc: 0.83106, logloss: 0.49429\n",
      "EPOCH 3  STEP 2472 train loss: 0.45314, train time: 330.86631, test loss: 0.50381, test time: 35.44565, auc: 0.82677, logloss: 0.50117\n",
      "EPOCH 4  STEP 3090 train loss: 0.43908, train time: 330.10525, test loss: 0.51506, test time: 35.41547, auc: 0.82158, logloss: 0.51264\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410242038\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410242038', epoch_num=20, batch_size=128, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50671, train time: 401.81548, test loss: 0.50630, test time: 36.55444, auc: 0.81854, logloss: 0.50626\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48381, train time: 401.55838, test loss: 0.49717, test time: 36.58751, auc: 0.82634, logloss: 0.49712\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.47508, train time: 401.51468, test loss: 0.49771, test time: 35.79174, auc: 0.82660, logloss: 0.49766\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 39536 train loss: 0.46804, train time: 401.62420, test loss: 0.49697, test time: 35.85628, auc: 0.82708, logloss: 0.49693\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 49420 train loss: 0.46172, train time: 401.39967, test loss: 0.49801, test time: 35.87401, auc: 0.82630, logloss: 0.49795\n",
      "EPOCH 5  STEP 59304 train loss: 0.45445, train time: 401.31547, test loss: 0.50406, test time: 36.13944, auc: 0.82569, logloss: 0.50401\n",
      "EPOCH 6  STEP 69188 train loss: 0.44602, train time: 401.53206, test loss: 0.50787, test time: 37.15412, auc: 0.82258, logloss: 0.50781\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410242129\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410242129', epoch_num=20, batch_size=128, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50635, train time: 407.96328, test loss: 0.49900, test time: 36.38063, auc: 0.82541, logloss: 0.49895\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48276, train time: 407.69017, test loss: 0.49640, test time: 36.36014, auc: 0.82770, logloss: 0.49635\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.47317, train time: 407.68434, test loss: 0.49457, test time: 35.58748, auc: 0.82883, logloss: 0.49451\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 39536 train loss: 0.46569, train time: 408.49319, test loss: 0.49737, test time: 35.66799, auc: 0.82869, logloss: 0.49732\n",
      "EPOCH 4  STEP 49420 train loss: 0.45776, train time: 408.20499, test loss: 0.50003, test time: 35.68565, auc: 0.82729, logloss: 0.49997\n",
      "EPOCH 5  STEP 59304 train loss: 0.44940, train time: 409.15830, test loss: 0.50458, test time: 35.93706, auc: 0.82481, logloss: 0.50452\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410242214\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410242214', epoch_num=20, batch_size=128, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50634, train time: 418.54084, test loss: 0.51341, test time: 36.74123, auc: 0.81552, logloss: 0.51336\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48326, train time: 418.55420, test loss: 0.50363, test time: 36.66373, auc: 0.82114, logloss: 0.50358\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.47270, train time: 418.64144, test loss: 0.50371, test time: 35.84158, auc: 0.82233, logloss: 0.50364\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 39536 train loss: 0.46396, train time: 417.58177, test loss: 0.50265, test time: 35.64001, auc: 0.82298, logloss: 0.50258\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 49420 train loss: 0.45540, train time: 417.27684, test loss: 0.50460, test time: 35.57868, auc: 0.82364, logloss: 0.50454\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 5  STEP 59304 train loss: 0.44663, train time: 415.75624, test loss: 0.51228, test time: 35.58817, auc: 0.82034, logloss: 0.51222\n",
      "EPOCH 6  STEP 69188 train loss: 0.43720, train time: 414.74394, test loss: 0.51741, test time: 36.11489, auc: 0.81891, logloss: 0.51734\n",
      "EPOCH 7  STEP 79072 train loss: 0.42672, train time: 414.61220, test loss: 0.52631, test time: 36.14540, auc: 0.81377, logloss: 0.52626\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410242315\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410242315', epoch_num=20, batch_size=128, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50600, train time: 427.91843, test loss: 0.49850, test time: 36.82530, auc: 0.82636, logloss: 0.49846\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48236, train time: 426.79314, test loss: 0.49627, test time: 36.89703, auc: 0.82876, logloss: 0.49622\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.47247, train time: 426.70253, test loss: 0.49311, test time: 36.03790, auc: 0.83025, logloss: 0.49305\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 39536 train loss: 0.46475, train time: 427.57676, test loss: 0.49411, test time: 36.13533, auc: 0.83006, logloss: 0.49406\n",
      "EPOCH 4  STEP 49420 train loss: 0.45640, train time: 427.54043, test loss: 0.50182, test time: 36.62182, auc: 0.82653, logloss: 0.50175\n",
      "EPOCH 5  STEP 59304 train loss: 0.44673, train time: 428.56864, test loss: 0.50361, test time: 36.59262, auc: 0.82629, logloss: 0.50354\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250002\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250002', epoch_num=20, batch_size=128, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50617, train time: 439.37524, test loss: 0.51393, test time: 37.05998, auc: 0.81386, logloss: 0.51387\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48380, train time: 439.54510, test loss: 0.50226, test time: 37.14501, auc: 0.82209, logloss: 0.50221\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.47291, train time: 438.43205, test loss: 0.49819, test time: 36.37466, auc: 0.82634, logloss: 0.49812\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 39536 train loss: 0.46391, train time: 439.40372, test loss: 0.49771, test time: 36.68804, auc: 0.82688, logloss: 0.49763\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 4  STEP 49420 train loss: 0.45537, train time: 439.43857, test loss: 0.50136, test time: 36.72551, auc: 0.82617, logloss: 0.50131\n",
      "EPOCH 5  STEP 59304 train loss: 0.44694, train time: 439.58092, test loss: 0.50978, test time: 36.19663, auc: 0.81997, logloss: 0.50972\n",
      "EPOCH 6  STEP 69188 train loss: 0.43718, train time: 439.49310, test loss: 0.51511, test time: 37.64535, auc: 0.81834, logloss: 0.51504\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 5e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250057\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250057', epoch_num=20, batch_size=128, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50464, train time: 399.52984, test loss: 0.49481, test time: 36.29121, auc: 0.82910, logloss: 0.49476\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.48021, train time: 398.86084, test loss: 0.49026, test time: 36.75447, auc: 0.83227, logloss: 0.49021\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.46222, train time: 398.15667, test loss: 0.49300, test time: 35.51917, auc: 0.83130, logloss: 0.49296\n",
      "EPOCH 3  STEP 39536 train loss: 0.44357, train time: 399.54227, test loss: 0.50388, test time: 35.81634, auc: 0.82486, logloss: 0.50383\n",
      "EPOCH 4  STEP 49420 train loss: 0.42459, train time: 399.34167, test loss: 0.51826, test time: 35.40852, auc: 0.81563, logloss: 0.51822\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 5e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250134\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250134', epoch_num=20, batch_size=128, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50328, train time: 408.53002, test loss: 0.49351, test time: 36.44946, auc: 0.83028, logloss: 0.49346\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47793, train time: 406.82054, test loss: 0.49022, test time: 36.40519, auc: 0.83231, logloss: 0.49016\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45817, train time: 406.51114, test loss: 0.49356, test time: 35.54766, auc: 0.83039, logloss: 0.49350\n",
      "EPOCH 3  STEP 39536 train loss: 0.43912, train time: 407.57011, test loss: 0.51356, test time: 35.49328, auc: 0.82341, logloss: 0.51351\n",
      "EPOCH 4  STEP 49420 train loss: 0.41877, train time: 405.33050, test loss: 0.52979, test time: 35.49145, auc: 0.81817, logloss: 0.52974\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 5e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250211\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250211', epoch_num=20, batch_size=128, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50306, train time: 420.68683, test loss: 0.49512, test time: 36.86113, auc: 0.82982, logloss: 0.49507\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47737, train time: 420.90461, test loss: 0.49135, test time: 36.85270, auc: 0.83132, logloss: 0.49129\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45851, train time: 420.75145, test loss: 0.49750, test time: 36.06124, auc: 0.82886, logloss: 0.49743\n",
      "EPOCH 3  STEP 39536 train loss: 0.44062, train time: 420.83477, test loss: 0.50505, test time: 36.06871, auc: 0.82557, logloss: 0.50499\n",
      "EPOCH 4  STEP 49420 train loss: 0.42149, train time: 420.86562, test loss: 0.51925, test time: 36.07357, auc: 0.81813, logloss: 0.51919\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 5e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250250\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250250', epoch_num=20, batch_size=128, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50297, train time: 427.79663, test loss: 0.49172, test time: 36.85532, auc: 0.83226, logloss: 0.49167\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47729, train time: 427.24615, test loss: 0.48667, test time: 36.90331, auc: 0.83703, logloss: 0.48663\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45866, train time: 428.24890, test loss: 0.49447, test time: 36.10066, auc: 0.83102, logloss: 0.49443\n",
      "EPOCH 3  STEP 39536 train loss: 0.43896, train time: 428.14213, test loss: 0.50349, test time: 36.44931, auc: 0.82674, logloss: 0.50346\n",
      "EPOCH 4  STEP 49420 train loss: 0.41850, train time: 428.54204, test loss: 0.52651, test time: 36.06569, auc: 0.81970, logloss: 0.52645\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 5e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250329\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250329', epoch_num=20, batch_size=128, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50358, train time: 441.37088, test loss: 0.49593, test time: 37.75806, auc: 0.82918, logloss: 0.49589\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47847, train time: 440.58256, test loss: 0.49401, test time: 37.22640, auc: 0.83092, logloss: 0.49396\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45956, train time: 440.32142, test loss: 0.49324, test time: 36.38228, auc: 0.83073, logloss: 0.49317\n",
      "EPOCH 3  STEP 39536 train loss: 0.44147, train time: 441.27987, test loss: 0.50719, test time: 36.73680, auc: 0.82351, logloss: 0.50713\n",
      "EPOCH 4  STEP 49420 train loss: 0.42244, train time: 442.18476, test loss: 0.52065, test time: 36.80840, auc: 0.81925, logloss: 0.52061\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-3 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250409\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250409', epoch_num=20, batch_size=128, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50492, train time: 401.15716, test loss: 0.49191, test time: 36.48004, auc: 0.83112, logloss: 0.49187\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47920, train time: 400.28629, test loss: 0.48680, test time: 36.46663, auc: 0.83513, logloss: 0.48675\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45844, train time: 400.24535, test loss: 0.49278, test time: 35.74592, auc: 0.83166, logloss: 0.49273\n",
      "EPOCH 3  STEP 39536 train loss: 0.43645, train time: 401.20502, test loss: 0.50409, test time: 35.83164, auc: 0.82726, logloss: 0.50405\n",
      "EPOCH 4  STEP 49420 train loss: 0.41228, train time: 400.06122, test loss: 0.51959, test time: 36.08203, auc: 0.81787, logloss: 0.51955\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-3 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250445\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250445', epoch_num=20, batch_size=128, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50362, train time: 409.70486, test loss: 0.48931, test time: 36.47358, auc: 0.83330, logloss: 0.48926\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47733, train time: 407.34849, test loss: 0.48701, test time: 36.48395, auc: 0.83501, logloss: 0.48695\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45885, train time: 406.72537, test loss: 0.49090, test time: 35.53660, auc: 0.83308, logloss: 0.49085\n",
      "EPOCH 3  STEP 39536 train loss: 0.43984, train time: 407.21486, test loss: 0.50765, test time: 35.51535, auc: 0.82961, logloss: 0.50762\n",
      "EPOCH 4  STEP 49420 train loss: 0.41860, train time: 405.10808, test loss: 0.52175, test time: 35.55929, auc: 0.82373, logloss: 0.52170\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-3 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250523\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250523', epoch_num=20, batch_size=128, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50419, train time: 423.75944, test loss: 0.49167, test time: 37.84586, auc: 0.83357, logloss: 0.49162\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47759, train time: 423.44368, test loss: 0.48735, test time: 37.04246, auc: 0.83461, logloss: 0.48729\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45713, train time: 421.31760, test loss: 0.49758, test time: 36.80760, auc: 0.83044, logloss: 0.49753\n",
      "EPOCH 3  STEP 39536 train loss: 0.43458, train time: 424.32266, test loss: 0.50667, test time: 36.24133, auc: 0.82641, logloss: 0.50662\n",
      "EPOCH 4  STEP 49420 train loss: 0.40758, train time: 422.24315, test loss: 0.52623, test time: 36.20998, auc: 0.81789, logloss: 0.52619\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-3 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250601\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250601', epoch_num=20, batch_size=128, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50408, train time: 431.12612, test loss: 0.48777, test time: 36.98158, auc: 0.83525, logloss: 0.48773\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47750, train time: 430.41921, test loss: 0.48620, test time: 36.98221, auc: 0.83886, logloss: 0.48615\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45761, train time: 430.57805, test loss: 0.49317, test time: 36.13728, auc: 0.83171, logloss: 0.49313\n",
      "EPOCH 3  STEP 39536 train loss: 0.43495, train time: 431.56746, test loss: 0.50339, test time: 36.19969, auc: 0.82810, logloss: 0.50334\n",
      "EPOCH 4  STEP 49420 train loss: 0.40938, train time: 431.50388, test loss: 0.53664, test time: 36.51507, auc: 0.81551, logloss: 0.53660\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 128 1e-3 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250641\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250641', epoch_num=20, batch_size=128, lr=0.001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 9884 train loss: 0.50461, train time: 442.41521, test loss: 0.49372, test time: 38.01519, auc: 0.83026, logloss: 0.49367\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 19768 train loss: 0.47835, train time: 442.46119, test loss: 0.49048, test time: 37.31866, auc: 0.83313, logloss: 0.49043\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs128_lr1e-3_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 29652 train loss: 0.45802, train time: 443.70351, test loss: 0.49131, test time: 36.52286, auc: 0.83281, logloss: 0.49124\n",
      "EPOCH 3  STEP 39536 train loss: 0.43562, train time: 442.24967, test loss: 0.50653, test time: 36.49203, auc: 0.82501, logloss: 0.50649\n",
      "EPOCH 4  STEP 49420 train loss: 0.40855, train time: 442.32536, test loss: 0.53064, test time: 37.00394, auc: 0.81662, logloss: 0.53061\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 1e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250721\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250721', epoch_num=20, batch_size=1024, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.51847, train time: 332.80190, test loss: 0.50977, test time: 34.89469, auc: 0.81718, logloss: 0.50882\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48606, train time: 334.53525, test loss: 0.50605, test time: 34.95824, auc: 0.82006, logloss: 0.50502\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47932, train time: 330.78819, test loss: 0.50482, test time: 35.05049, auc: 0.82113, logloss: 0.50382\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 4944 train loss: 0.47444, train time: 330.74096, test loss: 0.50514, test time: 35.04175, auc: 0.82035, logloss: 0.50417\n",
      "EPOCH 4  STEP 6180 train loss: 0.47006, train time: 330.86088, test loss: 0.50555, test time: 36.31575, auc: 0.82069, logloss: 0.50453\n",
      "EPOCH 5  STEP 7416 train loss: 0.46565, train time: 332.12302, test loss: 0.50646, test time: 34.87898, auc: 0.82120, logloss: 0.50538\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 6  STEP 8652 train loss: 0.46273, train time: 329.82004, test loss: 0.51140, test time: 34.77706, auc: 0.82162, logloss: 0.51024\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 7  STEP 9888 train loss: 0.46041, train time: 329.21479, test loss: 0.50872, test time: 35.11721, auc: 0.82016, logloss: 0.50776\n",
      "EPOCH 8  STEP 11124 train loss: 0.45796, train time: 329.43410, test loss: 0.50934, test time: 34.54402, auc: 0.82133, logloss: 0.50828\n",
      "EPOCH 9  STEP 12360 train loss: 0.45543, train time: 327.07955, test loss: 0.50730, test time: 34.98631, auc: 0.82172, logloss: 0.50627\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 10  STEP 13596 train loss: 0.45248, train time: 325.49292, test loss: 0.51142, test time: 34.44949, auc: 0.81993, logloss: 0.51040\n",
      "EPOCH 11  STEP 14832 train loss: 0.44904, train time: 325.47438, test loss: 0.51441, test time: 34.47760, auc: 0.81844, logloss: 0.51328\n",
      "EPOCH 12  STEP 16068 train loss: 0.44452, train time: 325.12811, test loss: 0.51951, test time: 35.04002, auc: 0.81829, logloss: 0.51857\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 1e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250840\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250840', epoch_num=20, batch_size=1024, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.51679, train time: 334.60616, test loss: 0.50028, test time: 36.24196, auc: 0.82717, logloss: 0.49934\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48526, train time: 334.46333, test loss: 0.49489, test time: 34.98895, auc: 0.82903, logloss: 0.49392\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47687, train time: 332.44976, test loss: 0.49604, test time: 34.95086, auc: 0.82867, logloss: 0.49505\n",
      "EPOCH 3  STEP 4944 train loss: 0.47093, train time: 332.54653, test loss: 0.49968, test time: 34.94733, auc: 0.82893, logloss: 0.49875\n",
      "EPOCH 4  STEP 6180 train loss: 0.46679, train time: 332.60406, test loss: 0.49761, test time: 36.33115, auc: 0.82799, logloss: 0.49659\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 1e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250911\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250911', epoch_num=20, batch_size=1024, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.51746, train time: 334.34987, test loss: 0.50583, test time: 34.81075, auc: 0.82108, logloss: 0.50485\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48548, train time: 333.88054, test loss: 0.50372, test time: 35.78380, auc: 0.82261, logloss: 0.50260\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47778, train time: 332.50934, test loss: 0.50389, test time: 34.85620, auc: 0.82215, logloss: 0.50280\n",
      "EPOCH 3  STEP 4944 train loss: 0.47159, train time: 332.10994, test loss: 0.50572, test time: 35.90465, auc: 0.82133, logloss: 0.50460\n",
      "EPOCH 4  STEP 6180 train loss: 0.46668, train time: 332.64249, test loss: 0.50536, test time: 34.80761, auc: 0.82133, logloss: 0.50440\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 1e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410250942\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410250942', epoch_num=20, batch_size=1024, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.51562, train time: 337.96768, test loss: 0.50080, test time: 35.13917, auc: 0.82524, logloss: 0.49974\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48469, train time: 335.85122, test loss: 0.49708, test time: 35.06499, auc: 0.82772, logloss: 0.49600\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47666, train time: 335.87114, test loss: 0.49655, test time: 35.21208, auc: 0.82814, logloss: 0.49551\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 4944 train loss: 0.47045, train time: 335.86901, test loss: 0.49776, test time: 35.13155, auc: 0.82757, logloss: 0.49673\n",
      "EPOCH 4  STEP 6180 train loss: 0.46556, train time: 335.40178, test loss: 0.50131, test time: 35.77293, auc: 0.82542, logloss: 0.50024\n",
      "EPOCH 5  STEP 7416 train loss: 0.46078, train time: 335.09445, test loss: 0.50373, test time: 35.07908, auc: 0.82550, logloss: 0.50274\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 1e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251020\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251020', epoch_num=20, batch_size=1024, lr=0.0001, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.51589, train time: 338.83057, test loss: 0.50514, test time: 35.07970, auc: 0.82117, logloss: 0.50417\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48621, train time: 336.71638, test loss: 0.50211, test time: 36.41341, auc: 0.82376, logloss: 0.50113\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47881, train time: 340.21746, test loss: 0.50350, test time: 34.97926, auc: 0.82378, logloss: 0.50240\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr1e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 4944 train loss: 0.47225, train time: 340.32429, test loss: 0.50263, test time: 35.04105, auc: 0.82328, logloss: 0.50161\n",
      "EPOCH 4  STEP 6180 train loss: 0.46758, train time: 336.96159, test loss: 0.50438, test time: 34.99826, auc: 0.82289, logloss: 0.50335\n",
      "EPOCH 5  STEP 7416 train loss: 0.46389, train time: 339.41792, test loss: 0.50493, test time: 35.83700, auc: 0.82274, logloss: 0.50387\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 5e-4 20 2 2 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251057\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251057', epoch_num=20, batch_size=1024, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=2, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.50673, train time: 333.25080, test loss: 0.49808, test time: 34.80416, auc: 0.82656, logloss: 0.49706\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48271, train time: 328.43069, test loss: 0.49584, test time: 34.70334, auc: 0.82937, logloss: 0.49471\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47290, train time: 328.01275, test loss: 0.49693, test time: 35.03544, auc: 0.82841, logloss: 0.49588\n",
      "EPOCH 3  STEP 4944 train loss: 0.46188, train time: 328.34483, test loss: 0.50071, test time: 34.52815, auc: 0.82648, logloss: 0.49980\n",
      "EPOCH 4  STEP 6180 train loss: 0.45046, train time: 326.93380, test loss: 0.50471, test time: 34.57933, auc: 0.82378, logloss: 0.50369\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 5e-4 20 2 3 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251128\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251128', epoch_num=20, batch_size=1024, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=3, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.50594, train time: 332.38265, test loss: 0.49744, test time: 35.56433, auc: 0.83021, logloss: 0.49649\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48208, train time: 332.07303, test loss: 0.49085, test time: 34.64002, auc: 0.83248, logloss: 0.48979\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.46971, train time: 329.81766, test loss: 0.49423, test time: 35.12598, auc: 0.83283, logloss: 0.49298\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 3  STEP 4944 train loss: 0.45642, train time: 329.28146, test loss: 0.50548, test time: 34.79599, auc: 0.83024, logloss: 0.50450\n",
      "EPOCH 4  STEP 6180 train loss: 0.44183, train time: 328.45685, test loss: 0.50751, test time: 34.54885, auc: 0.82529, logloss: 0.50631\n",
      "EPOCH 5  STEP 7416 train loss: 0.42619, train time: 326.26930, test loss: 0.52486, test time: 34.33292, auc: 0.81934, logloss: 0.52367\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 5e-4 20 2 4 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251205\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251205', epoch_num=20, batch_size=1024, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=4, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.50605, train time: 337.05378, test loss: 0.49782, test time: 36.19054, auc: 0.82776, logloss: 0.49685\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48188, train time: 335.29648, test loss: 0.49518, test time: 34.95109, auc: 0.82965, logloss: 0.49397\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.47021, train time: 333.22571, test loss: 0.49653, test time: 34.90720, auc: 0.82930, logloss: 0.49553\n",
      "EPOCH 3  STEP 4944 train loss: 0.45778, train time: 333.19131, test loss: 0.49938, test time: 36.25321, auc: 0.82748, logloss: 0.49829\n",
      "EPOCH 4  STEP 6180 train loss: 0.44430, train time: 335.50913, test loss: 0.50967, test time: 34.89050, auc: 0.82292, logloss: 0.50874\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 5e-4 20 2 5 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251236\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251236', epoch_num=20, batch_size=1024, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.50557, train time: 337.02511, test loss: 0.49572, test time: 35.04235, auc: 0.83007, logloss: 0.49467\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48191, train time: 335.13975, test loss: 0.49100, test time: 36.28575, auc: 0.83262, logloss: 0.48987\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.46941, train time: 337.53723, test loss: 0.49316, test time: 34.99536, auc: 0.83197, logloss: 0.49195\n",
      "EPOCH 3  STEP 4944 train loss: 0.45603, train time: 335.15199, test loss: 0.49723, test time: 34.99531, auc: 0.82916, logloss: 0.49620\n",
      "EPOCH 4  STEP 6180 train loss: 0.44180, train time: 335.10765, test loss: 0.51301, test time: 34.99279, auc: 0.82417, logloss: 0.51192\n",
      "---------------bs, lr, epoch, export share/spcf, convert arch, gru---------- 1024 5e-4 20 2 6 128,32 AIGRU DIN\n",
      "max hist len 5\n",
      "202410251307\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202410251307', epoch_num=20, batch_size=1024, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, task='ctr', algo='DIN', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, dcn_deep_arch=[200, 80], dcn_cross_num=3, deepfm_latent_dim=16, deepfm_deep_arch=[200, 80], cin_layer_units=[50, 50], num_attn_heads=1, attn_size=64, num_attn_layers=3, res_conn=True, attn_scale=True, reduction_ratio=0.5, bilinear_type='field_all', gnn_layer_num=2, reuse_graph_layer=True, dien_gru='AIGRU')\n",
      "Train data size: 1265059 Test data size: 141523\n",
      "HEA\n",
      "convert module: HEA\n",
      "/gpfs/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "EPOCH 0  STEP 1236 train loss: 0.50543, train time: 340.09915, test loss: 0.49982, test time: 35.32001, auc: 0.82760, logloss: 0.49886\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 1  STEP 2472 train loss: 0.48193, train time: 338.27039, test loss: 0.49735, test time: 35.30819, auc: 0.83011, logloss: 0.49637\n",
      "model save in ./model/amz/ctr/DIN/WDA_Emb32_epoch20_bs1024_lr5e-4_cosine_cnvt_arch_128,32_cnvt_type_HEA_eprt_2_wd0_drop0.0_hl200,80_cl3_augment_True/DIN.pt\n",
      "EPOCH 2  STEP 3708 train loss: 0.46885, train time: 338.42511, test loss: 0.49954, test time: 36.53456, auc: 0.82891, logloss: 0.49831\n",
      "EPOCH 3  STEP 4944 train loss: 0.45565, train time: 340.11595, test loss: 0.50259, test time: 35.25302, auc: 0.82644, logloss: 0.50151\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://n088.hpc:8888/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home2/kkms4641/Recsys/Open-World-Knowledge-Augmented-Recommendation/RS\")\n",
    "!python run_ctr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost with params: lr=0.1, depth=6, n_est=100, subsample=0.8, colsample=0.8\n",
      "max hist len 5\n",
      "202411132200\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/rerank/XGBoostReranker/XGB_Emb32_epoch50_lr0.1_depth6_nest100_sub0.8_col0.8', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202411132200', epoch_num=50, batch_size=256, lr=0.0001, weight_decay=0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, metric_scope=[1, 3, 5, 7], task='rerank', algo='XGBoostReranker', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=5, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, n_head=2, ff_dim=128, attn_dp=0.0, temperature=0.5, n_layers=3, max_depth=6, n_estimators=100, feature_mlp_arch=[256, 128, 64])\n",
      "Train data size: 320368 Test data size: 35834\n",
      "HEA\n",
      "convert module: HEA\n",
      "metric scope [1, 3, 5, 7]\n",
      "test loss: 0.00000, test time: 38.79587\n",
      "@1, MAP: 0.23720, NDCG: 0.23720, CLICK: 0.23720\n",
      "@3, MAP: 0.36898, NDCG: 0.27010, CLICK: 0.71795\n",
      "@5, MAP: 0.39297, NDCG: 0.34451, CLICK: 1.19066\n",
      "@7, MAP: 0.38944, NDCG: 0.42478, CLICK: 1.66515\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:25] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:34] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:01:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:25] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:27] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:34] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:02:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:06] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:13] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [22:03:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS\")\n",
    "!python run_rerank_XGBoost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
