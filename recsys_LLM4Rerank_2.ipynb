{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  5 01:50:48 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  |   00000000:34:00.0 Off |                  Off |\n",
      "| 30%   29C    P8             19W /  300W |       2MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               On  |   00000000:35:00.0 Off |                  Off |\n",
      "| 30%   32C    P8             27W /  300W |       2MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               On  |   00000000:36:00.0 Off |                  Off |\n",
      "| 30%   30C    P8             28W /  300W |       2MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000               On  |   00000000:37:00.0 Off |                  Off |\n",
      "| 30%   28C    P8             15W /  300W |       2MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Testing with bs=256, lr=5e-4, wd=0, heads=8 -----------\n",
      "max hist len 5\n",
      "202412051417\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202412051417', epoch_num=50, batch_size=256, lr=0.0005, weight_decay=0.0, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, metric_scope=[1, 3, 5, 7], task='rerank', algo='LLM4Rerank_1', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, n_head=2, ff_dim=128, attn_dp=0.0, temperature=1.0, n_layers=3, max_depth=6, n_estimators=100, feature_mlp_arch=[256, 128, 64], llm_heads=8, llm_layers=6, llm_ff_dim=512, norm_scale=1.0, layer_weight_init=1.0, neighbor_weight_init=1.0)\n",
      "Train data size: 320368 Test data size: 35834\n",
      "HEA\n",
      "convert module: HEA\n",
      "metric scope [1, 3, 5, 7]\n",
      "test loss: 1.09314, test time: 43.87263\n",
      "@1, MAP: 0.23720, NDCG: 0.23720, CLICK: 0.23720\n",
      "@3, MAP: 0.36898, NDCG: 0.27010, CLICK: 0.71795\n",
      "@5, MAP: 0.39297, NDCG: 0.34451, CLICK: 1.19066\n",
      "@7, MAP: 0.38944, NDCG: 0.42478, CLICK: 1.66515\n",
      "/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "epoch: 0, train time: 436.90189, test loss: 0.38389, test time: 43.37479\n",
      "@1, MAP: 0.56725, NDCG: 0.56725, CLICK: 0.56725\n",
      "@3, MAP: 0.65796, NDCG: 0.59564, CLICK: 1.52020\n",
      "@5, MAP: 0.64942, NDCG: 0.67034, CLICK: 2.10984\n",
      "@7, MAP: 0.64042, NDCG: 0.70442, CLICK: 2.31252\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0/LLM4Rerank_1.pt\n",
      "epoch: 1, train time: 438.33371, test loss: 0.35433, test time: 43.34422\n",
      "@1, MAP: 0.60630, NDCG: 0.60630, CLICK: 0.60630\n",
      "@3, MAP: 0.68676, NDCG: 0.63500, CLICK: 1.61743\n",
      "@5, MAP: 0.67768, NDCG: 0.70414, CLICK: 2.19222\n",
      "@7, MAP: 0.67049, NDCG: 0.72912, CLICK: 2.33926\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0/LLM4Rerank_1.pt\n",
      "epoch: 2, train time: 437.65941, test loss: 0.34264, test time: 43.42602\n",
      "@1, MAP: 0.61779, NDCG: 0.61779, CLICK: 0.61779\n",
      "@3, MAP: 0.69413, NDCG: 0.64616, CLICK: 1.64785\n",
      "@5, MAP: 0.68497, NDCG: 0.71339, CLICK: 2.21748\n",
      "@7, MAP: 0.67875, NDCG: 0.73569, CLICK: 2.34646\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0/LLM4Rerank_1.pt\n",
      "epoch: 3, train time: 438.24377, test loss: 0.33982, test time: 43.06034\n",
      "@1, MAP: 0.62086, NDCG: 0.62086, CLICK: 0.62086\n",
      "@3, MAP: 0.69711, NDCG: 0.64968, CLICK: 1.65483\n",
      "@5, MAP: 0.68761, NDCG: 0.71631, CLICK: 2.22144\n",
      "@7, MAP: 0.68186, NDCG: 0.73817, CLICK: 2.34811\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0/LLM4Rerank_1.pt\n",
      "epoch: 4, train time: 438.43616, test loss: 0.34259, test time: 43.87489\n",
      "@1, MAP: 0.62187, NDCG: 0.62187, CLICK: 0.62187\n",
      "@3, MAP: 0.69784, NDCG: 0.65166, CLICK: 1.66180\n",
      "@5, MAP: 0.68831, NDCG: 0.71721, CLICK: 2.22590\n",
      "@7, MAP: 0.68235, NDCG: 0.73820, CLICK: 2.34757\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd0/LLM4Rerank_1.pt\n",
      "epoch: 5, train time: 437.67839, test loss: 0.34652, test time: 42.51980\n",
      "@1, MAP: 0.61997, NDCG: 0.61997, CLICK: 0.61997\n",
      "@3, MAP: 0.69589, NDCG: 0.64896, CLICK: 1.65633\n",
      "@5, MAP: 0.68686, NDCG: 0.71506, CLICK: 2.22054\n",
      "@7, MAP: 0.68058, NDCG: 0.73692, CLICK: 2.34702\n",
      "epoch: 6, train time: 437.51983, test loss: 0.35743, test time: 43.41444\n",
      "@1, MAP: 0.61657, NDCG: 0.61657, CLICK: 0.61657\n",
      "@3, MAP: 0.69408, NDCG: 0.64703, CLICK: 1.65223\n",
      "@5, MAP: 0.68538, NDCG: 0.71375, CLICK: 2.21837\n",
      "@7, MAP: 0.67923, NDCG: 0.73565, CLICK: 2.34568\n",
      "epoch: 7, train time: 437.58651, test loss: 0.36813, test time: 43.40951\n",
      "@1, MAP: 0.61350, NDCG: 0.61350, CLICK: 0.61350\n",
      "@3, MAP: 0.69176, NDCG: 0.64351, CLICK: 1.64076\n",
      "@5, MAP: 0.68285, NDCG: 0.71091, CLICK: 2.21044\n",
      "@7, MAP: 0.67692, NDCG: 0.73351, CLICK: 2.34202\n",
      "--------------- Testing with bs=256, lr=5e-4, wd=1e-4, heads=8 -----------\n",
      "max hist len 5\n",
      "202412051523\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202412051523', epoch_num=50, batch_size=256, lr=0.0005, weight_decay=0.0001, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, metric_scope=[1, 3, 5, 7], task='rerank', algo='LLM4Rerank_1', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, n_head=2, ff_dim=128, attn_dp=0.0, temperature=1.0, n_layers=3, max_depth=6, n_estimators=100, feature_mlp_arch=[256, 128, 64], llm_heads=8, llm_layers=6, llm_ff_dim=512, norm_scale=1.0, layer_weight_init=1.0, neighbor_weight_init=1.0)\n",
      "Train data size: 320368 Test data size: 35834\n",
      "HEA\n",
      "convert module: HEA\n",
      "metric scope [1, 3, 5, 7]\n",
      "test loss: 1.09314, test time: 43.80622\n",
      "@1, MAP: 0.23720, NDCG: 0.23720, CLICK: 0.23720\n",
      "@3, MAP: 0.36898, NDCG: 0.27010, CLICK: 0.71795\n",
      "@5, MAP: 0.39297, NDCG: 0.34451, CLICK: 1.19066\n",
      "@7, MAP: 0.38944, NDCG: 0.42478, CLICK: 1.66515\n",
      "/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "epoch: 0, train time: 438.71909, test loss: 0.38445, test time: 43.48262\n",
      "@1, MAP: 0.56781, NDCG: 0.56781, CLICK: 0.56781\n",
      "@3, MAP: 0.65860, NDCG: 0.59540, CLICK: 1.51867\n",
      "@5, MAP: 0.64958, NDCG: 0.66976, CLICK: 2.10657\n",
      "@7, MAP: 0.64054, NDCG: 0.70449, CLICK: 2.31238\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4/LLM4Rerank_1.pt\n",
      "epoch: 1, train time: 439.05013, test loss: 0.35332, test time: 43.45006\n",
      "@1, MAP: 0.60786, NDCG: 0.60786, CLICK: 0.60786\n",
      "@3, MAP: 0.68870, NDCG: 0.63740, CLICK: 1.62201\n",
      "@5, MAP: 0.67919, NDCG: 0.70599, CLICK: 2.19646\n",
      "@7, MAP: 0.67238, NDCG: 0.73056, CLICK: 2.34063\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4/LLM4Rerank_1.pt\n",
      "epoch: 2, train time: 438.19886, test loss: 0.34525, test time: 43.38590\n",
      "@1, MAP: 0.61648, NDCG: 0.61648, CLICK: 0.61648\n",
      "@3, MAP: 0.69315, NDCG: 0.64489, CLICK: 1.64450\n",
      "@5, MAP: 0.68445, NDCG: 0.71249, CLICK: 2.21427\n",
      "@7, MAP: 0.67803, NDCG: 0.73518, CLICK: 2.34593\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4/LLM4Rerank_1.pt\n",
      "epoch: 3, train time: 438.32597, test loss: 0.34096, test time: 43.44759\n",
      "@1, MAP: 0.62103, NDCG: 0.62103, CLICK: 0.62103\n",
      "@3, MAP: 0.69681, NDCG: 0.65003, CLICK: 1.65764\n",
      "@5, MAP: 0.68785, NDCG: 0.71622, CLICK: 2.22286\n",
      "@7, MAP: 0.68175, NDCG: 0.73788, CLICK: 2.34836\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4/LLM4Rerank_1.pt\n",
      "epoch: 4, train time: 439.13339, test loss: 0.34656, test time: 43.46133\n",
      "@1, MAP: 0.62128, NDCG: 0.62128, CLICK: 0.62128\n",
      "@3, MAP: 0.69682, NDCG: 0.65064, CLICK: 1.65982\n",
      "@5, MAP: 0.68801, NDCG: 0.71563, CLICK: 2.21996\n",
      "@7, MAP: 0.68154, NDCG: 0.73763, CLICK: 2.34741\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-4/LLM4Rerank_1.pt\n",
      "epoch: 5, train time: 438.20333, test loss: 0.34617, test time: 43.34981\n",
      "@1, MAP: 0.62014, NDCG: 0.62014, CLICK: 0.62014\n",
      "@3, MAP: 0.69519, NDCG: 0.64878, CLICK: 1.65480\n",
      "@5, MAP: 0.68660, NDCG: 0.71467, CLICK: 2.21873\n",
      "@7, MAP: 0.68039, NDCG: 0.73666, CLICK: 2.34590\n",
      "epoch: 6, train time: 439.11363, test loss: 0.35480, test time: 43.51201\n",
      "@1, MAP: 0.61651, NDCG: 0.61651, CLICK: 0.61651\n",
      "@3, MAP: 0.69296, NDCG: 0.64555, CLICK: 1.64857\n",
      "@5, MAP: 0.68393, NDCG: 0.71211, CLICK: 2.21418\n",
      "@7, MAP: 0.67791, NDCG: 0.73449, CLICK: 2.34367\n",
      "epoch: 7, train time: 438.41556, test loss: 0.37016, test time: 43.52702\n",
      "@1, MAP: 0.61255, NDCG: 0.61255, CLICK: 0.61255\n",
      "@3, MAP: 0.69014, NDCG: 0.64188, CLICK: 1.63803\n",
      "@5, MAP: 0.68233, NDCG: 0.70917, CLICK: 2.20545\n",
      "@7, MAP: 0.67586, NDCG: 0.73244, CLICK: 2.34057\n",
      "--------------- Testing with bs=256, lr=5e-4, wd=1e-3, heads=8 -----------\n",
      "max hist len 5\n",
      "202412051628\n",
      "parameters Namespace(data_dir='../data/amz/proc_data', save_dir='./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-3', reload_path='', setting_path='', device='cuda', seed=1234, output_dim=1, timestamp='202412051628', epoch_num=50, batch_size=256, lr=0.0005, weight_decay=0.001, adam_betas='0.9,0.999', adam_epsilon=1e-08, lr_sched='cosine', warmup_ratio=0.0, dropout=0.0, convert_dropout=0.0, grad_norm=0, test=False, patience=3, metric_scope=[1, 3, 5, 7], task='rerank', algo='LLM4Rerank_1', augment=True, aug_prefix='bert_avg', convert_type='HEA', max_hist_len=5, embed_dim=32, final_mlp_arch=[200, 80], convert_arch=[128, 32], export_num=2, top_expt_num=4, specific_export_num=6, auxi_loss_weight=0, hidden_size=64, rnn_dp=0.0, n_head=2, ff_dim=128, attn_dp=0.0, temperature=1.0, n_layers=3, max_depth=6, n_estimators=100, feature_mlp_arch=[256, 128, 64], llm_heads=8, llm_layers=6, llm_ff_dim=512, norm_scale=1.0, layer_weight_init=1.0, neighbor_weight_init=1.0)\n",
      "Train data size: 320368 Test data size: 35834\n",
      "HEA\n",
      "convert module: HEA\n",
      "metric scope [1, 3, 5, 7]\n",
      "test loss: 1.09314, test time: 43.35663\n",
      "@1, MAP: 0.23720, NDCG: 0.23720, CLICK: 0.23720\n",
      "@3, MAP: 0.36898, NDCG: 0.27010, CLICK: 0.71795\n",
      "@5, MAP: 0.39297, NDCG: 0.34451, CLICK: 1.19066\n",
      "@7, MAP: 0.38944, NDCG: 0.42478, CLICK: 1.66515\n",
      "/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/optimization.py:139: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  exp_avg.mul_(beta1).add_(-beta1 + 1.0, grad)\n",
      "epoch: 0, train time: 436.83973, test loss: 0.38828, test time: 43.24507\n",
      "@1, MAP: 0.56511, NDCG: 0.56511, CLICK: 0.56511\n",
      "@3, MAP: 0.65609, NDCG: 0.59322, CLICK: 1.51524\n",
      "@5, MAP: 0.64745, NDCG: 0.66769, CLICK: 2.10264\n",
      "@7, MAP: 0.63878, NDCG: 0.70264, CLICK: 2.30957\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-3/LLM4Rerank_1.pt\n",
      "epoch: 1, train time: 438.61422, test loss: 0.35410, test time: 43.32649\n",
      "@1, MAP: 0.60604, NDCG: 0.60604, CLICK: 0.60604\n",
      "@3, MAP: 0.68741, NDCG: 0.63625, CLICK: 1.61924\n",
      "@5, MAP: 0.67820, NDCG: 0.70457, CLICK: 2.19172\n",
      "@7, MAP: 0.67105, NDCG: 0.72941, CLICK: 2.33828\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-3/LLM4Rerank_1.pt\n",
      "epoch: 2, train time: 436.25136, test loss: 0.34385, test time: 43.11628\n",
      "@1, MAP: 0.61648, NDCG: 0.61648, CLICK: 0.61648\n",
      "@3, MAP: 0.69352, NDCG: 0.64657, CLICK: 1.64980\n",
      "@5, MAP: 0.68488, NDCG: 0.71306, CLICK: 2.21650\n",
      "@7, MAP: 0.67861, NDCG: 0.73544, CLICK: 2.34621\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-3/LLM4Rerank_1.pt\n",
      "epoch: 3, train time: 434.13615, test loss: 0.33949, test time: 42.96608\n",
      "@1, MAP: 0.62033, NDCG: 0.62033, CLICK: 0.62033\n",
      "@3, MAP: 0.69626, NDCG: 0.64968, CLICK: 1.65656\n",
      "@5, MAP: 0.68746, NDCG: 0.71588, CLICK: 2.22121\n",
      "@7, MAP: 0.68140, NDCG: 0.73758, CLICK: 2.34741\n",
      "model save in ./model/amz/rerank/LLM4Rerank_1/LLM_Emb32_epoch50_bs256_lr5e-4_heads8_wd1e-3/LLM4Rerank_1.pt\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/main_rerank.py\", line 254, in <module>\n",
      "    train(args)\n",
      "  File \"/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/main_rerank.py\", line 155, in train\n",
      "    res, eval_loss, eval_time = eval(model, test_loader, metric_scope, True)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/main_rerank.py\", line 33, in eval\n",
      "    for batch, data in enumerate(test_loader):\n",
      "  File \"/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home2/kkms4641/miniconda3/envs/LLM/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/gpfs/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS/dataset.py\", line 78, in __getitem__\n",
      "    item_aug_vec = [torch.tensor(self.item_aug_data[str(self.id2item[str(idx)])]).float()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home2/kkms4641/Open-World-Knowledge-Augmented-Recommendation/RS\")\n",
    "!python run_rerank_LLM4Rerank_11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
